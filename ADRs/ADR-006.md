# ADR-006 — Queue Abstraction & Future Migration to SQS/RabbitMQ

**Status:** Accepted
**Decision Date:** 2025-11-29
**Authors:** Abhishek

## Context

The orchestrator requires a reliable task-dispatch layer for:

* Scheduling execution tasks (provision, run, collect, teardown)
* Ensuring at-least-once delivery
* Handling retries, backoff, and DLQ behavior
* Decoupling API/Scheduler from Workers
* Supporting future high-scale distributed deployments

**Sprint-2** must operate **locally**, without cloud dependencies.
But **Sprint-3** will integrate with **AWS SQS** or **RabbitMQ**, depending on infra-bench-platform design.

Therefore, the system needs a **queue abstraction layer** that:

* Works in-memory for local dev/tests (Sprint-2)
* Has feature parity with cloud queues (visibility timeout, retries, DLQ)
* Allows seamless migration to SQS or RabbitMQ
* Does not leak backend-specific details into business logic

This requires a **Queue Interface Layer** + **Task Envelope Model**.

## Requirements

* At-least-once delivery
* Retry metadata (`attempt`, `max_attempts`, `next_attempt_ts`)
* Visibility timeout / lock semantics
* Dead-letter queue (DLQ) behavior
* JSON-serializable task envelope
* Backend-agnostic
* Pluggable adapters: InMemoryQueue → SQSQueue → RabbitQueue
* Strict decoupling from scheduler/worker logic
* Worker-safe semantics under concurrency

## Options

### Option A — Custom Queue Abstraction + Pluggable Backends (Recommended)

Define a generic Python interface:

```
Queue.push(task_envelope)
Queue.pop()
Queue.extend_visibility(task_id, delta)
Queue.ack(task_id)
Queue.nack(task_id)
```

Implement:

* InMemoryQueue (Sprint-2)
* SQSQueue (Sprint-3)
* Optional: RabbitMQQueue (future)

### Option B — Use Celery/RQ/Kombu

Complex, heavyweight, opinionated; harder to integrate with custom runner lifecycle.

### Option C — Direct AWS SQS Client in Business Logic

Breaks modularity; hard to test; prevents alternative backends.

## Decision

Use **Option A**:
Implement a **Queue Abstraction Layer** with interchangeable backend implementations.

Sprint-2 uses **InMemoryQueue** with at-least-once semantics.
Sprint-3 introduces **SQSQueue** and **DLQQueue**.
RabbitMQ is optional and can be added if infra team requires it.

## Rationale

* **Testability:** Unit + integration tests can run without AWS/local Rabbit.
* **Decoupling:** Scheduler and Worker logic remains backend-agnostic.
* **Flexibility:** Easy migration to SQS in Sprint-3.
* **Consistency:** Same interface ensures consistent behavior across environments.
* **Minimal vendor lock-in:** Supports SQS, RabbitMQ, or future cloud queues.
* **Deterministic local dev:** In-memory queue makes local runs predictable.

Direct integration with SQS (Option C) would tightly couple business logic to AWS and break CI/local workflows.

Celery/RQ (Option B) would introduce unnecessary complexity and hide critical semantics (visibility timeout, DLQ routing) required by a test orchestrator.

## Queue Model

### Task Envelope

A normalized representation stored in queue:

```
{
  "task_id": "<UUIDv4>",
  "execution_id": "<ULID>",
  "reservation_id": "<ULID>",
  "type": "provision | run | collect | teardown",
  "payload": {...},
  "attempt": 0,
  "max_attempts": 5,
  "visibility_timeout": 30,
  "created_at": "...",
  "next_attempt_ts": "..."
}
```

### Required Behaviors

* `push()` inserts a task
* `pop()` returns a locked task (invisible briefly)
* `ack()` confirms completion
* `nack()` triggers retry or DLQ
* `extend_visibility()` keeps long-running tasks alive

### DLQ Semantics

* After `max_attempts`, task moves to DLQ with metadata for debugging.
* DLQ entries may notify Ops through webhook/alert.

## Backend Implementations

### InMemoryQueue (Sprint-2)

* Simple Python list/heap
* Tick-based visibility timeout
* Deterministic retry behavior
* Used in unit tests and local integration tests

### SQSQueue (Sprint-3)

* Uses AWS SQS FIFO or Standard (depending on cost/ordering)
* Visibility timeout controlled by API
* Automatic DLQ using SQS redrive policy
* Additional metadata stored in S3 or DynamoDB for debugging

### RabbitMQQueue (optional future)

* AMQP routing with worker acknowledgments
* Durability and fanout patterns

## Implementation Plan

### Sprint-2

* Create `queue/base.py` defining `QueueInterface` and `TaskEnvelope`.
* Implement `InMemoryQueue`.
* Integrate queue into scheduler/worker lifecycle.

### Sprint-3

* Implement `SQSQueue` with:

  * `ReceiveMessage`
  * `ChangeMessageVisibility`
  * `DeleteMessage`
  * DLQ redrive policy
* Add local integration tests with AWS LocalStack (optional).

### Cross-cutting:

* Add queue metrics (S4):

  * queue_length
  * task_failures
  * retry_count
* Add cost-aware retry strategy for Sprint-5.

## Acceptance Criteria

* Queue interface implemented with deterministic behavior.
* Scheduler and worker decoupled from backend type.
* InMemoryQueue fully tested for:

  * push/pop
  * visibility timeout
  * retries/nack
  * DLQ behavior
* SQS adapter stub exists (Sprint-3 placeholder).
* Documentation in `docs/architecture/queue.md`.

## Consequences

* Supports clean migration from local → AWS SQS.
* Reduces vendor lock-in.
* Clear testing boundary between business logic and infrastructure.
* Adds one extra abstraction layer, but benefits outweigh complexity.

---

**Summary:**
Implement a backend-agnostic **Queue Abstraction Layer** with an **InMemoryQueue** for Sprint-2 and migrate to **AWS SQS** in Sprint-3. This ensures testability, reliability, and flexibility across environments.
